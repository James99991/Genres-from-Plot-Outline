{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Multilabel Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Multi-Label Classification: An Overview Grigorios Tsoumakas, Ioannis Katakis`\n",
    "\n",
    "> Traditional single-label classification is concerned with learning from a set of examples that are\n",
    "associated with a single label \n",
    "\n",
    "- If the number of label = 2 its binary \n",
    "- If number of labels > 2 multi-class problem\n",
    "\n",
    ">In multi-label classification, the examples are associated with a set of labels Y ⊆ L. In the past, multilabel classification was mainly motivated by the tasks of text categorization and medical diagnosis.\n",
    "Text documents usually belong to more than one conceptual class. For example, a newspaper article\n",
    "concerning the reactions of the Christian church to the release of the Da Vinci Code film can be\n",
    "classified into both of the categories Society\\Religion and Arts\\Movies. Similarly in medical diagnosis,\n",
    "a patient may be suffering for example from diabetes and prostate cancer at the same time.\n",
    "\n",
    "![multi-label-table](external_images_for_notebooks/multi-label-table.png)\n",
    "\n",
    "## Methods\n",
    "\n",
    "https://scikit-learn.org/stable/modules/multiclass.html\n",
    "\n",
    "We can group the existing methods for multi-label classification into two main categories: a) problem\n",
    "transformation methods, and b) algorithm adaptation methods. \n",
    "\n",
    "Problem transformation methods \n",
    "- The first one (dubbed PT1) subjectively or randomly selects one of the multiple labels of each multi-label instance and discards the rest, while the second one (dubbed PT2) simply discards every multi-label instance from the multi-label data set. \n",
    "- These two problem transformation methods discard a lot of the information content of the original multilabel data set and are therefore not considered further in this work.\n",
    "- The third problem transformation method that we will mention (dubbed PT3), considers each different set of labels that exist in the multi-label data set as a single label. \n",
    "    - One label for sports, one for sports and politics, one for science and politics etc\n",
    "- The **most common** problem transformation method (dubbed PT4) learns |L| binary classifiers Hl: X → {l, ¬l} , one for each different label l in L. It transforms the original data set into |L| data sets Dl that contain all examples of the original data set, labelled as l if the labels of the original example contained l and as ¬l otherwise. It is the same solution used in order to deal with a single-label multiclass problem using a binary classifier. \n",
    "\n",
    "![multilabel_method_pt4](external_images_for_notebooks/multilabel_methd_pt4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "\n",
    "`A Unified View of Multi-Label Performance Measures: Xi-Zhu Wu 1 Zhi-Hua Zhou 1`\n",
    "\n",
    "> The fraction of misclassified labels\n",
    "\n",
    "https://stats.stackexchange.com/questions/336820/what-is-a-hamming-loss-will-we-consider-it-for-an-imbalanced-binary-classifier\n",
    "\n",
    "> The hamming loss (HL) is the fraction of the wrong labels to the total number of labels. Hence, for the binary case (imbalanced or not), HL=1-Accuracy as you wrote.\n",
    "\n",
    "> The HL thus presents one clear single-performance-value for multiple-label case in contrast to the precision/recall/f1 that can be evaluated only for independent binary classifiers for each label.\n",
    "\n",
    "https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff\n",
    "\n",
    "https://medium.com/towards-artificial-intelligence/understanding-multi-label-classification-model-and-accuracy-metrics-1b2a8e2648ca\n",
    "\n",
    "> Let’s see the scenario for the multi-label case using our example dataset. If question with id 241465 is classified with labels: ‘modeling’, ‘central-limit-theorem’, ‘degrees-of-freedom’ then what we can say? Actual class labels in the dataset were ‘statistical-significance’, ‘modeling’, ‘central-limit-theorem’, ‘degrees-of-freedom’ and ‘spurious-correlation’. Neither it is completely wrong prediction nor it is completely right. If we go for traditional correct vs total ratio based accuracy metric, definitely we won’t be able to judge the classifier. We need something to judge the partial correctness of a multi-label classifier.\n",
    "\n",
    "### Hamming Loss Metric\n",
    "\n",
    "> Instead of counting no of correctly classified data instance, Hamming Loss calculates loss generated in the bit string of class labels during prediction. It does XOR operation between the original binary string of class labels and predicted class labels for a data instance and calculates the average across the dataset. \n",
    "\n",
    "> hamming loss’ value ranges from 0 to 1. As it is a loss metric, its interpretation is reverse in nature unlike normal accuracy ratio. Lesser value of hamming loss indicates a better classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
